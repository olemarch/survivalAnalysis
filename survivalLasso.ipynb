{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Survival Analysis on TCGA High Grade Serous Ovarian Cancer",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install pandas numpy scikit-learn lifelines",
   "id": "aa929c564ac68785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lifelines.statistics import logrank_test\n",
    "from scipy import stats\n",
    "import datetime"
   ],
   "id": "527a8fb23c71835c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data and preprocess survival columns to a binary format",
   "id": "4659dc1f9e2e7c28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"./data/hgsoc_tcga_gdc_clinical_data.tsv\", sep='\\t')\n",
    "\n",
    "time_col = \"Overall Survival (Months)\"\n",
    "event_col_raw = \"Overall Survival Status\"\n",
    "event_col = 'Overall Survival Final'\n",
    "df = df.dropna(subset=[event_col_raw])\n",
    "\n",
    "df[event_col] = df[event_col_raw].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Ensure event_col is binary (1=event occurred/death, 0=censored)\n",
    "df[event_col] = df[event_col].astype(int)\n",
    "df[event_col].value_counts()"
   ],
   "id": "1acc675f7debd7f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Select features",
   "id": "373f449aa34b3710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "''' After careful consideration of the features, here are the ones I think would be the most informative given the information provided. Of course, the model can be further improved by using mutations, CNVs or other genomic biomarkers. Check out model_b to see how to I incorporate all biomarker and clinical information into a model. But for this exercise let's keep it simple and prioritize clinical features'''\n",
    "df= df[[\"Patient ID\", \"Sample ID\", \"Race Category\", \"FIGO Stage\", \"Oncotree Code\", \"Diagnosis Age\", \"Fraction Genome Altered\", time_col, event_col]]\n",
    "feature_columns = [\n",
    "    \"Diagnosis Age\",\n",
    "    \"Fraction Genome Altered\",\n",
    "    \"Race Category\",\n",
    "    \"FIGO Stage\",\n",
    "    \"Oncotree Code\",\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=[time_col, event_col,\n",
    "                       \"Diagnosis Age\",\n",
    "                       \"Fraction Genome Altered\",\n",
    "                       \"Race Category\",\n",
    "                       \"FIGO Stage\",\n",
    "                       \"Oncotree Code\"])\n",
    "\n",
    "# Convert to structured array needed by scikit-survival\n",
    "y = Surv.from_arrays(event=(df[event_col] == 1), time=df[time_col].values)\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "\n",
    "# Specify which columns are categorical and which are numeric. You would need to take a look at the data to do that \n",
    "cat_cols = [\"Race Category\", \"FIGO Stage\", \"Oncotree Code\"]\n",
    "num_cols = [\"Diagnosis Age\", \"Fraction Genome Altered\"]\n",
    "print(f\"Number of patients in the cohort: {df['Sample ID'].nunique()}\")\n"
   ],
   "id": "dd81007222c2c150",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build a preprocessing pipeline with scikit-learn",
   "id": "fe0226a51b4388d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# i love writing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Define categorical pipeline to process cat columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")"
   ],
   "id": "710ae6c055369d9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Coxnet with L1 penalty model and tune parameters",
   "id": "66a8b52b4c7973d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CoxnetSurvivalAnalysis allows fitting a path of solutions for given alphas.\n",
    "# We'll use GridSearchCV to select the best alpha by maximizing c-index.\n",
    "alphas = 10 ** np.linspace(-3, 1, 20)  # you can adjust the range\n",
    "\n",
    "# Define a simple function for c-index scoring in GridSearchCV\n",
    "def c_index_scorer(estimator, X_values, y_values):\n",
    "    predi = estimator.predict(X_values)\n",
    "    return concordance_index_censored(y_values['event'], y_values['time'], predi)[0]\n",
    "\n",
    "coxnet = CoxnetSurvivalAnalysis(l1_ratio=1.0, alpha_min_ratio=0.01)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", coxnet)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alphas\": [alphas]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipe, param_grid, scoring=c_index_scorer, cv=cv)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# See what you get for the best alpha\n",
    "best_alpha = best_model.alphas_[0]  # For L1-penalized Cox model, alphas_[0] contains the used alpha\n",
    "# Lets save feature coefficients\n",
    "final_coefs = best_model.coef_[0]\n",
    "\n",
    "#some helper variables\n",
    "feature_names_num = num_cols\n",
    "encoder = grid_search.best_estimator_.named_steps['preprocessing'].named_transformers_['cat'].named_steps['onehot']\n",
    "encoded_cat_names = encoder.get_feature_names_out(cat_cols)\n",
    "all_feature_names = feature_names_num + encoded_cat_names.tolist()\n",
    "\n",
    "# Print final coefficients\n",
    "print(\"Final Coefficients:\")\n",
    "for name, coef in zip(all_feature_names, final_coefs):\n",
    "    print(f\"{name}: {coef:.4f}\")\n",
    "\n",
    "# print best alpha value\n",
    "print(f\"Best alpha that we can choose: {best_alpha:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best of the best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV c-index:\", grid_search.best_score_)\n",
    "\n",
    "# Extract final model\n",
    "final_coxnet = best_model.named_steps[\"model\"]\n",
    "\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "feature_names_num = num_cols\n",
    "# Extract encoded categorical feature names\n",
    "encoder = best_model.named_steps[\"preprocessing\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "encoded_cat_names = encoder.get_feature_names_out(cat_cols)\n",
    "all_feature_names = feature_names_num + encoded_cat_names.tolist()\n",
    "\n",
    "print(\"Final coefficients at best alpha value:\")\n",
    "for fname, coef in zip(all_feature_names, final_coefs):\n",
    "    print(f\"{fname}: {coef}\")\n"
   ],
   "id": "bf34aca89bc81868",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Galculate Risk Scores and Kaplan-Meier (KM) Curves. Plot KM curves for High and Low Risk group. Use Log-Rank test, Breslow and Tarone-Ware tests. For shorter survival times use Wilcoxon test ",
   "id": "deadd91ccaf510cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# First, set up local functions for Breslow and Tarone-Ware weights\n",
    "def breslow_weights(at_risk):\n",
    "    return at_risk\n",
    "\n",
    "def tarone_ware_weights(at_risk):\n",
    "    return np.sqrt(at_risk)\n",
    "\n",
    "def wilcoxon_weights(events):\n",
    "    return events\n",
    "\n",
    "def weighted_logrank_test(time_high, time_low, event_high, event_low, weighting_function):\n",
    "    n_high = len(time_high)\n",
    "    n_low = len(time_low)\n",
    "    combined_times = np.concatenate([time_high, time_low])\n",
    "    combined_events = np.concatenate([event_high, event_low])\n",
    "    group_indicator = np.concatenate([np.ones(n_high), np.zeros(n_low)])\n",
    "\n",
    "    sorted_indices = np.argsort(combined_times)\n",
    "    times = combined_times[sorted_indices]\n",
    "    events = combined_events[sorted_indices]\n",
    "    groups = group_indicator[sorted_indices]\n",
    "\n",
    "    at_risk_high = np.cumsum(groups[::-1])[::-1]\n",
    "    at_risk_low = np.cumsum((1 - groups)[::-1])[::-1]\n",
    "    at_risk_total = at_risk_high + at_risk_low\n",
    "\n",
    "    weights = weighting_function(at_risk_total)\n",
    "    observed_high = np.cumsum(events * groups * weights)\n",
    "    expected_high = np.cumsum(events * (at_risk_high / at_risk_total) * weights)\n",
    "    test_statistic = np.sum((observed_high - expected_high) ** 2 / (expected_high + 1e-10))\n",
    "    # Test statistic (chi-squared)\n",
    "    p_value = 1 - stats.chi2.cdf(test_statistic, df=1)\n",
    "    return test_statistic, p_value"
   ],
   "id": "1975d4aa869717e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate risk scores for High and Low risk groups and perform log-rank and wilcoxon tests, implement automated decision about model value based on ci-index score",
   "id": "bd6b4ee2b20304c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "risk_scores = best_model.predict(X)\n",
    "\n",
    "# Split patients into high and low risk by median\n",
    "median_score = np.median(risk_scores)\n",
    "high_risk_group = risk_scores >= median_score\n",
    "low_risk_group = risk_scores < median_score\n",
    "\n",
    "# Extract time and event data for each group\n",
    "time_high = df.loc[high_risk_group, time_col]\n",
    "event_high = df.loc[high_risk_group, event_col]\n",
    "\n",
    "time_low = df.loc[low_risk_group, time_col]\n",
    "event_low = df.loc[low_risk_group, event_col]\n",
    "\n",
    "# Perform Log-Rank Test\n",
    "logrank_results = logrank_test(time_high, time_low, event_high, event_low)\n",
    "\n",
    "# Calculate Breslow, Tarone and logrank p-values\n",
    "test_stat_breslow, breslow_p = weighted_logrank_test(time_high, time_low, event_high, event_low, breslow_weights)\n",
    "test_stat_tarone, tarone_p = weighted_logrank_test(time_high, time_low, event_high, event_low, tarone_ware_weights)\n",
    "test_stat_logrank, logrank_p = logrank_results.test_statistic, logrank_results.p_value\n",
    "test_statistic_wilcoxon, p_value_wilcoxon = weighted_logrank_test(\n",
    "    time_high, time_low, event_high, event_low, wilcoxon_weights\n",
    ")\n",
    "print(f\"Wilcoxon Test: Test Statistic = {test_statistic_wilcoxon:.4f}, p-value = {p_value_wilcoxon:.4e}\")\n",
    "# create variable to make automated decision based on the ci-index score\n",
    "decision=0\n",
    "if grid_search.best_score_<0.5:\n",
    "    decision = 'terrible'\n",
    "elif grid_search.best_score_==0.5:\n",
    "    decision = 'random performance'\n",
    "elif grid_search.best_score_>0.5 and grid_search.best_score_<=0.8:\n",
    "    decision = 'above chance performance'\n",
    "elif grid_search.best_score_>0.8 and grid_search.best_score_<=0.95:\n",
    "    decision = 'good'\n",
    "elif grid_search.best_score_>0.95:\n",
    "    decision = 'excellent'\n",
    "else :\n",
    "    decision = 'missed bucket: rethink your code'"
   ],
   "id": "c39423f721b8fa0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fit Cox Proportional Hazard Model and calculate standard errors",
   "id": "5f1754470c2dfeaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "df_lifelines = df.copy()\n",
    "df_lifelines[\"event\"] = (df[event_col] == 1).astype(int)\n",
    "df_lifelines[\"time\"] = df[time_col]\n",
    "\n",
    "# Select covariates and survival data\n",
    "lifelines_columns = feature_columns + [\"time\", \"event\"]\n",
    "\n",
    "# Fit CoxPHFitter\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_lifelines[lifelines_columns], duration_col=\"time\", event_col=\"event\")\n",
    "\n",
    "# Extract coefficients and standard errors\n",
    "cph_summary = cph.summary\n",
    "coefficients = cph_summary[\"coef\"]\n",
    "standard_errors = cph_summary[\"se(coef)\"]\n",
    "\n",
    "print(\"Coefficients:\\n\", coefficients)\n",
    "print(\"Standard Errors:\\n\", standard_errors)"
   ],
   "id": "72984198177828ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate covariate effects on Survival with confidence intervals",
   "id": "7ce1ce900a6fe83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Define z-value for 95% CI\n",
    "z = 1.96\n",
    "\n",
    "# Calculate confidence intervals\n",
    "lower_ci = np.exp(final_coefs - z * standard_errors)\n",
    "upper_ci = np.exp(final_coefs + z * standard_errors)\n",
    "\n",
    "# Add to the covariate_effects DataFrame\n",
    "covariate_effects[\"Lower CI\"] = lower_ci\n",
    "covariate_effects[\"Upper CI\"] = upper_ci\n",
    "\n",
    "# Print covariate effects with CIs\n",
    "print(\"\\nCovariate Effects on Survival with Confidence Intervals:\")\n",
    "print(covariate_effects)"
   ],
   "id": "6ef4cf42ee72be8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##Plot Hazard Ratios and Confidence Intervals in the notebook",
   "id": "2c12bf1d49f74b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot hazard ratios with error bars\n",
    "plt.errorbar(\n",
    "    covariate_effects[\"Hazard Ratio (HR)\"],  # HR values\n",
    "    covariate_effects[\"Feature\"],  # Covariate names\n",
    "    xerr=[covariate_effects[\"Hazard Ratio (HR)\"] - covariate_effects[\"Lower CI\"],\n",
    "          covariate_effects[\"Upper CI\"] - covariate_effects[\"Hazard Ratio (HR)\"]],\n",
    "    fmt='o', color='blue', ecolor='gray', elinewidth=2, capsize=4\n",
    ")\n",
    "\n",
    "# Add a vertical line at HR=1\n",
    "plt.axvline(1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"Hazard Ratios with Confidence Intervals\")\n",
    "plt.xlabel(\"Hazard Ratio\")\n",
    "plt.ylabel(\"Covariate\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "20d6b8d01b8683c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up PDF reporting and write analysis plots into the PDF",
   "id": "b47a682cf9738209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "report_filename = f\"./reports/Survival_Analysis_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\"\n",
    "from matplotlib.figure import Figure\n",
    "with PdfPages(report_filename) as pdf:\n",
    "\n",
    "    # Figure 1: KM Curves\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    kmf_high = KaplanMeierFitter()\n",
    "    kmf_low = KaplanMeierFitter()\n",
    "\n",
    "    kmf_high.fit(time_high, event_high, label='High Risk')\n",
    "    ax = kmf_high.plot_survival_function(ci_show=True, color='red')\n",
    "\n",
    "    kmf_low.fit(time_low, event_low, label='Low Risk')\n",
    "    kmf_low.plot_survival_function(ci_show=True, ax=ax, color='blue')\n",
    "\n",
    "    plt.title(\"Kaplan-Meier Survival Curves (High vs Low Risk)\")\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.text(0.2, 0.2, f'Log-Rank Test p-value: {logrank_p:.4f}', fontsize=8, transform=plt.gca().transAxes)\n",
    "    plt.text(0.2, 0.15, f'Breslow Test p-value: {breslow_p:.4f}', fontsize=8, transform=plt.gca().transAxes)\n",
    "    plt.text(0.2, 0.1, f'Tarone-Ware Test p-value: {tarone_p:.4f}', fontsize=8, transform=plt.gca().transAxes)\n",
    "    plt.text(0.2, 0.05, f'Wilcoxon Test p-value: {p_value_wilcoxon:.4f}', fontsize=8, transform=plt.gca().transAxes)\n",
    "\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Figure 2: Lasso Cox Coefficient Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sorted_indices = np.argsort(final_coefs)\n",
    "    plt.barh(np.array(all_feature_names)[sorted_indices], final_coefs[sorted_indices])\n",
    "    plt.title(\"Feature Coefficients from LASSO Cox Model\")\n",
    "    plt.xlabel(\"Coefficient\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Figure 3: Conclusions Page\n",
    "    fig = Figure()\n",
    "    text_ax = fig.add_subplot(111)\n",
    "    text_ax.axis('off')\n",
    "    conclusion_text = (\n",
    "        \"Conclusions:\\n\\n\"\n",
    "        f\"1. The best alpha chosen by cross-validation is {best_alpha:.4f}.\\n\"\n",
    "        f\"2. The cross-validated c-index was {grid_search.best_score_:.3f}, indicating {decision} model discriminative ability.\\n\"\n",
    "        f\"3. Patients stratified by median predicted risk scores show distinct survival curves, \"\n",
    "        f\"with the high-risk group demonstrating worse survival.\\n\"\n",
    "        f\"4. Statistical test results comparing survival curves:\\n\"\n",
    "        f\"   - Log-Rank Test p-value: {logrank_p:.4f}, Test-statistics: {test_stat_logrank:.4f}\\n\"\n",
    "        f\"   - Breslow Test p-value: {breslow_p:.4f}, Test-statistics: {test_stat_breslow:.4f}\\n\"\n",
    "        f\"   - Tarone-Ware Test p-value: {tarone_p:.4f}, Test-statistics: {test_stat_tarone:.4f}\\n\"\n",
    "        f\"   - Wilcoxon Test p-value: {p_value_wilcoxon:.4f}, Test-statistics: {test_statistic_wilcoxon:.4f}\\n\"\n",
    "\n",
    "        f\"5. The LASSO penalty shrinks some coefficients to zero, highlighting the most informative features.\\n\"\n",
    "    )\n",
    "    text_ax.text(0.01, 0.98, conclusion_text, verticalalignment='top', fontsize=12, wrap=True)\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Figure 4 Hazard ratios with confidence intervals from Cox Hazard Ratios Model\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(\n",
    "        covariate_effects[\"Hazard Ratio (HR)\"],\n",
    "        covariate_effects[\"Feature\"],\n",
    "        xerr=[covariate_effects[\"Hazard Ratio (HR)\"] - covariate_effects[\"Lower CI\"],\n",
    "              covariate_effects[\"Upper CI\"] - covariate_effects[\"Hazard Ratio (HR)\"]],\n",
    "        fmt='o', color='blue', ecolor='gray', elinewidth=2, capsize=4\n",
    "    )\n",
    "    plt.axvline(1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(\"Hazard Ratios with Confidence Intervals\")\n",
    "    plt.xlabel(\"Hazard Ratio\")\n",
    "    plt.ylabel(\"Covariate\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Save covariate effects table in the PDF\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.axis('off')\n",
    "    table = plt.table(cellText=covariate_effects.values,\n",
    "                      colLabels=covariate_effects.columns,\n",
    "                      loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.auto_set_column_width(col=list(range(len(covariate_effects.columns))))\n",
    "    plt.title(\"Covariate Effects on Survival\")\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Covariate analysis with confidence intervals added to {report_filename}\")"
   ],
   "id": "8b74ecee74ef8f77",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
